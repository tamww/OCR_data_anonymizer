{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98be1fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random, string, math, re, os\n",
    "import fitz\n",
    "# from pyhanlp import HanLP\n",
    "from faker import Faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "e7401156",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'cv2' has no attribute 'gapi_wip_gst_GStreamerPipeline'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mG:\\TMPTMP/ipykernel_14796/1859593385.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\Anaconda\\Main\\envs\\Tensorflow_2_1_NEW\\lib\\site-packages\\cv2\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 181\u001b[1;33m \u001b[0mbootstrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mG:\\Anaconda\\Main\\envs\\Tensorflow_2_1_NEW\\lib\\site-packages\\cv2\\__init__.py\u001b[0m in \u001b[0;36mbootstrap\u001b[1;34m()\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0msubmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m__collect_extra_submodules\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDEBUG\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 175\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0m__load_extra_py_code_for_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"cv2\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubmodule\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDEBUG\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    176\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mDEBUG\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Extra Python code for\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubmodule\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"is loaded\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\Anaconda\\Main\\envs\\Tensorflow_2_1_NEW\\lib\\site-packages\\cv2\\__init__.py\u001b[0m in \u001b[0;36m__load_extra_py_code_for_module\u001b[1;34m(base, name, enable_debug_print)\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[0mnative_module\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodule_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[0mpy_module\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodule_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0menable_debug_print\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\Anaconda\\Main\\envs\\Tensorflow_2_1_NEW\\lib\\importlib\\__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    125\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\Anaconda\\Main\\envs\\Tensorflow_2_1_NEW\\lib\\site-packages\\cv2\\gapi\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    299\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    300\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 301\u001b[1;33m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgapi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwip\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGStreamerPipeline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgapi_wip_gst_GStreamerPipeline\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: module 'cv2' has no attribute 'gapi_wip_gst_GStreamerPipeline'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "3f433958",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "1a2163a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract \n",
    "from PIL import Image, ImageDraw, ImageSequence, ImageFont"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ba928c",
   "metadata": {},
   "source": [
    "## Basic Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80878e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_text = []\n",
    "fake = Faker(\"zh_tw\")\n",
    "doc = ''\n",
    "colorList = fitz.utils.getColorList()\n",
    "font_language = {1:'zh', 2:'en'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69fca9f",
   "metadata": {},
   "source": [
    "#### Read file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "662b8c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readFile(path):\n",
    "    global doc, doc_text\n",
    "    pdf_path = path\n",
    "    doc = fitz.open(pdf_path)\n",
    "    for page in doc:\n",
    "        text = page.get_text()\n",
    "        doc_text.append(text)\n",
    "    return doc_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec96bd36",
   "metadata": {},
   "source": [
    "#### Fake Name Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "34918fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conditional_fake(cond):\n",
    "    while True:\n",
    "        x = fake.name()\n",
    "        if cond(x):\n",
    "            yield x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6e4acb",
   "metadata": {},
   "source": [
    "## Chinese Parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df484b01",
   "metadata": {},
   "source": [
    "#### LAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d18e833",
   "metadata": {},
   "outputs": [],
   "source": [
    "from LAC import LAC\n",
    "lac = LAC(mode=\"lac\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "5d0ff6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_LAC(sentence):\n",
    "    user_name_lis = []\n",
    "    _result = lac.run(sentence)\n",
    "#     print(_result)\n",
    "    for _index, _label in enumerate(_result[1]):\n",
    "        if _label == \"PER\":\n",
    "            user_name_lis.append(_result[0][_index])\n",
    "    return user_name_lis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baccbde2",
   "metadata": {},
   "source": [
    "#### LTP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1c2b3a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ltp import LTP\n",
    "ltp = LTP(\"LTP/small\")  # 默认加载 Small 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "bf50b912",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_LTP(sentence):\n",
    "    user_name_list = []\n",
    "    try:\n",
    "        output = ltp.pipeline([sentence], tasks=[\"cws\", \"pos\", \"ner\", \"srl\", \"dep\", \"sdp\"])\n",
    "        # 使用字典格式作为返回结果\n",
    "#         print(output.cws)  # print(output[0]) / print(output['cws']) # 也可以使用下标访问\n",
    "#         print(output.pos)\n",
    "#         print(output.sdp)\n",
    "        pos_length = len(output.pos[0])\n",
    "        i = 0\n",
    "        while i < pos_length:\n",
    "            if(pos_length - i)>=3:\n",
    "                temp = '-'.join(output.pos[0][i:i+3])\n",
    "                # search for pattern 'nh', 'nh', 'n'\n",
    "                if(temp=='nh-nh-n' or temp=='o-nh-ws'):\n",
    "                    user_name_list.append(''.join(output.cws[0][i:i+3]))\n",
    "                    i += 3\n",
    "                    continue\n",
    "\n",
    "            if(pos_length - i)>=2:\n",
    "                temp = '-'.join(output.pos[0][i:i+2])\n",
    "\n",
    "                if(temp=='nh-nh'):\n",
    "                    # search for pattern nh + nh \n",
    "                    user_name_list.append(''.join(output.cws[0][i:i+2]))\n",
    "                    i += 2\n",
    "                    continue\n",
    "\n",
    "                elif(temp=='nh-n'):\n",
    "                    # search for pattern nh + n\n",
    "                    user_name_list.append(''.join(output.cws[0][i:i+2]))\n",
    "                    i += 2\n",
    "                    continue\n",
    "            # search for pattern nh\n",
    "            if(output.pos[0][i] == 'nh'):\n",
    "                user_name_list.append(output.cws[0][i])\n",
    "            i += 1\n",
    "    except Exception as e:\n",
    "        print(text, e)\n",
    "    finally:\n",
    "        return user_name_list\n",
    "\n",
    "#         elif type == 'ltp':\n",
    "#             output = ltp.pipeline([sentence], tasks=[\"cws\", \"pos\", \"ner\", \"srl\", \"dep\", \"sdp\"])\n",
    "#             # 使用字典格式作为返回结果\n",
    "#             print(output.cws)  # print(output[0]) / print(output['cws']) # 也可以使用下标访问\n",
    "#             print(output.pos)\n",
    "#             print(output.sdp)\n",
    "#             print(\" \")\n",
    "#             for i in range(len(output.pos)):\n",
    "#                 if(output.pos[i] == 'nh'):\n",
    "#                     user_name_lis.append(output.cws[i])\n",
    "#     #  1.   2.   3. \n",
    "    # [['丁', '小姐']]\n",
    "    # [['nh', 'n']]\n",
    "    # [{'head': [2, 0], 'label': ['FEAT', 'Root']}]\n",
    "    # [['陳大文']]\n",
    "    # [['nh']]\n",
    "    # [{'head': [0], 'label': ['Root']}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a21df80",
   "metadata": {},
   "source": [
    "#### JIEBA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "234d28e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "import jieba.posseg as pseg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "d94d9f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_jieba(text):\n",
    "#     words = pseg.cut(text) #jieba默认模式\n",
    "    # jieba.enable_paddle() #启动paddle模式。 0.40版之后开始支持，早期版本不支持\n",
    "#     words = pseg.cut(text,use_paddle=True) #paddle模式\n",
    "#     for word, flag in words:\n",
    "#         print('%s %s' % (word, flag))\n",
    "    per_list = []  # 人名列表\n",
    "    word_list = jieba.lcut(text)\n",
    "#     print(word_list)\n",
    "    for word in word_list:\n",
    "        if len(word)==1:  # 不加判断会爆\n",
    "            continue\n",
    "        words = pseg.cut(word, use_paddle=True)  # paddle模式\n",
    "#         print(list(words))\n",
    "        word, flag = list(words)[0]\n",
    "        if flag=='PER':  # 这里写成LOC是地名\n",
    "            per_list.append(word)\n",
    "    per_list = list(set(per_list))\n",
    "#     print(per_list)\n",
    "    return per_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010e1ca7",
   "metadata": {},
   "source": [
    "#### Extraction Model Handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "55bcef0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_name(sentence: str, type='lac'):\n",
    "    user_name_lis = []\n",
    "#     print(sentence)\n",
    "    try:\n",
    "        if type == 'lac':\n",
    "            lacResult = extract_LAC(sentence)\n",
    "            if len(lacResult)==0:\n",
    "                ltpResult = extract_LTP(sentence)\n",
    "                user_name_lis.extend(ltpResult)\n",
    "            user_name_lis.extend(lacResult)\n",
    "        elif type == 'ltp':\n",
    "            ltpResult = extract_LTP(sentence)\n",
    "            user_name_lis.extend(ltpResult)\n",
    "        elif type == 'jieba':\n",
    "            jiebaResult = extract_jieba(sentence)\n",
    "            user_name_lis.extend(jiebaResult)\n",
    "        else:\n",
    "            raise Exception('type not suppose')\n",
    "        return user_name_lis\n",
    "    except Exception as e:\n",
    "        print(text, e)\n",
    "    finally:\n",
    "        return user_name_lis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "dbc86269",
   "metadata": {},
   "outputs": [],
   "source": [
    "def searchNameMatch(_text, opt='lac'):\n",
    "    nameExtracted = extract_name(_text,opt)\n",
    "    return nameExtracted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561d4c52",
   "metadata": {},
   "source": [
    "#### Find Word Distance (to find font file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "0e3eee19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find word distance\n",
    "import Levenshtein\n",
    "\n",
    "def getFontPath(font_name, lang = 'zh'):\n",
    "    base_path = 'c:/windows/fonts'\n",
    "    end_path = ''\n",
    "    fileName_search = font_name.lower()\n",
    "    fileNames = []\n",
    "    for fileName in os.listdir(base_path):\n",
    "        fileName_inList = fileName.replace(\" \",\"\").replace(r'_-',\"\").lower().split('.')\n",
    "        # print(fileName_inList)\n",
    "        if((Levenshtein.distance(fileName_search, fileName_inList[0])<5 \n",
    "            or (fileName_inList[0] in fileName_search))):\n",
    "#            and fileName_inList[1]=='ttf'):\n",
    "            fileNames.append(fileName)\n",
    "    if(len(fileNames)>0):\n",
    "        base_path = base_path+'/'+fileNames[0]\n",
    "    else:\n",
    "        if not (lang=='zh'):\n",
    "            base_path +='/times.ttf'\n",
    "        else:\n",
    "            base_path +='/kaiu.ttf'\n",
    "    return base_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf049d8",
   "metadata": {},
   "source": [
    "## Search ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "4168a88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def searchIDMatch(_text):\n",
    "#     print(_text)\n",
    "#     reg = r\"([a-zA-Z][0-9]{6})\\s*\\(\\s*[0-9]\\s*\\)\"\n",
    "    reg = r\"[a-zA-Z][0-9]{6}\\s*\\([0-9]\\)\"\n",
    "    trackID = re.findall(reg,_text)\n",
    "    if(trackID):\n",
    "        return(trackID)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "865e6583",
   "metadata": {},
   "outputs": [],
   "source": [
    "def id_generator(size=6, chars=string.ascii_uppercase + string.digits):\n",
    "    return ''.join(random.choice(chars) for _ in range(size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a596d7",
   "metadata": {},
   "source": [
    "## Rewrite the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "1f0dee4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rewriteName(name_tuple, _blockText, _page):\n",
    "    nameExtracted = name_tuple[0]\n",
    "    newName = name_tuple[1]\n",
    "    nameLang = name_tuple[2]\n",
    "\n",
    "#         if(nameExtracted):\n",
    "        # print(nameExtracted)\n",
    "        ##\n",
    "        # get text format\n",
    "#                 print(blockText)\n",
    "    fontSize = _blockText['lines'][0]['spans'][0]['size']\n",
    "    fontType = _blockText['lines'][0]['spans'][0]['font']\n",
    "    fontColor = _blockText['lines'][0]['spans'][0]['color']\n",
    "    fontdir = _blockText['lines'][0]['dir']\n",
    "\n",
    "    text_loca = _page.search_for(nameExtracted)\n",
    "\n",
    "    fontColorRGB = fitz.utils.getColor(colorList[fontColor].lower())\n",
    "    fontRotationDegree = math.atan2(fontdir[0], fontdir[1])*180/math.pi - _page.rotation\n",
    "    fontFilePath = getFontPath(fontType,font_language[nameLang])\n",
    "\n",
    "    print('---> Name Change')\n",
    "    print(f'{nameExtracted} -> {newName}')\n",
    "    print(f'Location: {text_loca[0]} | Font Size: {fontSize} | Font Type: {fontType} | Font Path: {fontFilePath}')\n",
    "    print(f'Color: {fontColor} -> {fontColorRGB} : {colorList[fontColor]} | Rotation: {fontdir} -> {fontRotationDegree} | Page Rotation: {_page.rotation}')\n",
    "    ##\n",
    "    # define font \n",
    "    _page.draw_rect(\n",
    "        text_loca[0],\n",
    "        color=(1,1,1),\n",
    "        fill=(1,1,1),\n",
    "        width=0\n",
    "    )\n",
    "    _page.insert_font(fontname=fontType,fontfile=fontFilePath, fontbuffer=newName , set_simple=False )\n",
    "    _page.insert_text(\n",
    "        fitz.Point(text_loca[0][2],text_loca[0][3]),\n",
    "        newName,\n",
    "        fontname=fontType,\n",
    "        fontsize=fontSize,\n",
    "        lineheight=1,\n",
    "#         color=(0.5,0.5,0),\n",
    "        color=fontColorRGB, \n",
    "        # fill=(1,1,1,1), \n",
    "        render_mode=0, \n",
    "        border_width=1, \n",
    "        rotate=fontRotationDegree, \n",
    "        morph=None, \n",
    "        overlay=True\n",
    "    )\n",
    "\n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ab7661",
   "metadata": {},
   "source": [
    "### Search Each Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "6b3adbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeText(fileType='PDF'):\n",
    "    global fake\n",
    "    for i in range(len(doc)):\n",
    "        print(f\">>Current editing page {i} \")\n",
    "        page = doc[i]\n",
    "        if not page.is_wrapped:\n",
    "            page.wrap_contents() \n",
    "        if fileType==\"PDF\":\n",
    "            textPage = page.get_textpage().extractDICT()\n",
    "            for blockText in textPage['blocks']:\n",
    "    #             text = blockText['lines'][0]['spans'][0]['text']\n",
    "                modifyList = []\n",
    "                for textLine in blockText['lines']:\n",
    "                    for textSpan in textLine['spans']:\n",
    "                        text = textSpan['text']\n",
    "\n",
    "                        list_id_found = searchIDMatch(text)\n",
    "                        if(list_id_found):\n",
    "                            for idd in list_id_found:\n",
    "                                randomID = id_generator(1,string.ascii_uppercase) + id_generator(6,string.digits) + \"(\"+id_generator(1,string.digits)+\")\"\n",
    "                                modifyList.append([idd, randomID,2])\n",
    "                        ltp\n",
    "                        if(len(text)>0 and (text.count(\" \") != len(text))):\n",
    "    #                         list_name_found = searchNameMatch(text,'ltp')\n",
    "    #                         if(list_name_found):\n",
    "    #                             for _name in list_name_found:\n",
    "    #                                 modifyList.append([_name, fake.name(),1])\n",
    "                        #lac\n",
    "                            list_name_found = searchNameMatch(text,'lac')\n",
    "                            if(list_name_found):\n",
    "                                for _name in list_name_found:\n",
    "                                    # generate fake naem\n",
    "                                    zhWordCheck = re.findall(r'[\\u4e00-\\u9fff]+', _name)\n",
    "                                    if zhWordCheck:\n",
    "                                        fake = Faker(\"zh_tw\")\n",
    "                                    else:\n",
    "                                        fake = Faker(\"en\")\n",
    "                                    modifyList.append([_name, fake.name(),1])\n",
    "    #                         list_name_found = searchNameMatch(text,'ltp')\n",
    "    #                         print(list_name_found)\n",
    "    #                         print('-------------')\n",
    "                if(len(modifyList)>0):\n",
    "                    for obj in modifyList:\n",
    "                        rewriteName(obj,blockText,page)\n",
    "        \n",
    "        elif fileType==\"IMAGEPDF\":\n",
    "            img_list = page.get_images()\n",
    "#             print(img_list)\n",
    "            for num, img in enumerate(img_list):\n",
    "                plt.plot(img)\n",
    "#                 img_name = f\"./{i + 1}_{num + 1}.png\" # save image\n",
    "#                 pix = fitz.Pixmap(doc, img[0])  # image转pixmap\n",
    "#                 if pix.n - pix.alpha >= 4:  # 如果差值大于等于4，需要转化后才能保存为png\n",
    "#                     pix = fitz.Pixmap(fitz.csRGB, pix)\n",
    "#                 pix.save(img_name) # 存储图片\n",
    "#                 pix = None  # 释放Pixmap资源\n",
    "#         #         image = Image.open(img_name)\n",
    "#                 image = cv2.imread(img_name,0) #直接读为灰度图像\n",
    "#                 image = 255 * np.array(image).astype('uint8')\n",
    "#                 ret,thresh3 = cv2.threshold(image,127,255,cv2.THRESH_TRUNC)\n",
    "#                 text = pytesseract.image_to_string(thresh3,\"eng\") # 调用tesseract，使用俄语库\n",
    "#                 print(text)\n",
    "#                 print(\" \")\n",
    "        \n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af40739",
   "metadata": {},
   "source": [
    "## Process PDF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d38b00b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccb1f58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718a9ff9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfa74ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1a2b401b",
   "metadata": {},
   "source": [
    "## Process Image File"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1290ce6",
   "metadata": {},
   "source": [
    "## Main Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "967e11f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def workflow(inPath, outPath, inName,outName, typeDoc):\n",
    "    global doc, doc_text\n",
    "    doc = ''\n",
    "    print(\"Step1: reading documents\")\n",
    "    fileread = ''\n",
    "    try:\n",
    "        fileread = readFile(inPath + inName)\n",
    "    except IOError:\n",
    "        print(\"Error: file not found\")\n",
    "    else:\n",
    "        print('text changed successfully')\n",
    "    \n",
    "#     print(fileread)\n",
    "    \n",
    "    print(\"**************************************************\")\n",
    "    print(\"Step2: modify documents\")\n",
    "    try:\n",
    "        writeText(typeDoc)\n",
    "    except Exception as e:\n",
    "        print('Error: write text failed')\n",
    "        print(e)\n",
    "    else:\n",
    "        print('text changed successfully')\n",
    "    \n",
    "#     print(\"**************************************************\")\n",
    "#     print(\"Step3: save documents\")\n",
    "#     try:\n",
    "#         doc.save(outPath + outName)\n",
    "#     except Exception as e:\n",
    "#         print('Error: file saved failed')\n",
    "#         print(e)\n",
    "#     else:\n",
    "#         print('file saved successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83376ac",
   "metadata": {},
   "source": [
    "# Starting Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "45d2f63f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step1: reading documents\n",
      "text changed successfully\n",
      "**************************************************\n",
      "Step2: modify documents\n",
      ">>Current editing page 0 \n",
      "Error: write text failed\n",
      "name 'plt' is not defined\n"
     ]
    }
   ],
   "source": [
    "## Initiate Workflow\n",
    "workflow('', '', '2.pdf', \"2_out.pdf\", \"IMAGEPDF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795b6a19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2eba8aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185c1a3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe0d8d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df919489",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95e28dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2140082b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#             page.insert_text(\n",
    "#                 point=fitz.Point(text_loca[0][0],text_loca[0][2]),\n",
    "#                 text=fake.name(),\n",
    "#                 fontsize=10,\n",
    "# #                 fontname=fontType,\n",
    "#                 fontfile=,\n",
    "#                 color=(0,0,0),\n",
    "#                 lineheight=12\n",
    "#             )           \n",
    "#             print(text_loca)\n",
    "            # write text\n",
    "#             page.add_redact_annot(\n",
    "#                 quad=text_loca[0],\n",
    "#                 text=fake.name(),\n",
    "#                 fontname=fontType,\n",
    "#                 fontfile=getFontPath(fontType),\n",
    "#                 fontsize=fontSize,\n",
    "#                 text_color=(1,1,1),\n",
    "#                 cross_out=False\n",
    "#             )\n",
    "#             page.apply_redactions()\n",
    "\n",
    "        # insert the text\n",
    "#                 page.insert_text(\n",
    "#                     fitz.Point(text_loca[0][2],text_loca[0][3]),\n",
    "#                     nameExtracted,\n",
    "#                     fontname=fontType,\n",
    "#                     fontsize=fontSize,\n",
    "#                     lineheight=1,\n",
    "#                     color=fontColorRGB, \n",
    "#                     fill=(1,1,1,1), \n",
    "#                     render_mode=0, \n",
    "#                     border_width=1, \n",
    "#                     rotate=fontRotationDegree, \n",
    "#                     morph=None, \n",
    "#                     overlay=True\n",
    "#                 )\n",
    "\n",
    "    # _page.insert_textbox(\n",
    "    #     text_loca[0],\n",
    "    #     newName,\n",
    "    #     fontname=fontType,\n",
    "    #     fontsize=fontSize,\n",
    "    #     lineheight=2,\n",
    "    #     color=fontColorRGB, \n",
    "    #     fill=(1,1,1,1), \n",
    "    #     render_mode=0, \n",
    "    #     border_width=1, \n",
    "    #     # rotate=fontRotationDegree, \n",
    "    #     rotate=0, \n",
    "    #     morph=None, \n",
    "    #     overlay=False\n",
    "    # )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6090fd21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6506fb7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache G:\\TMPTMP\\jieba.cache\n",
      "Loading model cost 0.674 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我 r\n",
      "爱 v\n",
      "北京 ns\n",
      "天安门 ns\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
